apiVersion: batch/v1
kind: Job
metadata:
  labels:
    k8s-app: finetune-llama
    qcloud-app: finetune-llama
  name: finetune-llama
  namespace: demo
spec:
  completions: 1
  parallelism: 1
  template:
    metadata:
      annotations:
        eks.tke.cloud.tencent.com/gpu-type: 'V100'
        eks.tke.cloud.tencent.com/root-cbs-size: '50'
      labels:
        k8s-app: finetune-llama
        qcloud-app: finetune-llama
    spec:
      containers:
      - image: ccr.ccs.tencentyun.com/halewang/finetune-llama2-lora:v1
        args:
          - "finetune.py"
          - "--base_model=/data/models/Llama-2-7b-hf"
          - "--data_path=/data/datasets/code_alpaca_20k.json"
          - "--output_dir=/data/output/checkpoint"
          - "--val_set_size=2000"
          - "--wandb_project=llama2"
          - "--wandb_run_name=test-llama2-finetune"
          - "--wandb_watch=false" 
          - "--wandb_log_model=true"
        env:
        - name: WANDB_API_KEY
          value: '7c0bce62a9099f221976712486bd888ad7c0553f'
        imagePullPolicy: Always
        name: finetune
        resources:
          limits:
            nvidia.com/gpu: "1"
          requests:
            nvidia.com/gpu: "1"
        securityContext:
          privileged: false
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /data
          name: models
      dnsPolicy: ClusterFirst
      nodeSelector:
        node.kubernetes.io/instance-type: eklet
      imagePullSecrets:
      - name: qcloudregistrykey
      restartPolicy: Never
      schedulerName: default-scheduler
      securityContext: {}
      volumes:
      - name: models
        persistentVolumeClaim:
          claimName: finetune-llama-pvc